#!/usr/bin/env python

from __future__ import print_function, division
# from autoaugment import RandAugment
from randaugment import RandAugment, ImageNetPolicy

import torch
import math
import random
from collections import defaultdict
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
from sklearn.metrics import f1_score   
import torchvision
from torchvision import datasets, models, transforms
from torch import Tensor
import matplotlib.pyplot as plt
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torch.utils.data import Dataset , DataLoader, TensorDataset
import time
import os
import copy
from sklearn.utils.multiclass import type_of_target

print("Using mixup fixed corrects")

def imshow(inp, title=None, save_dir="/home/hlcv_team030/hlcv_team030/1.png"):
    # show an image
    """Imshow for Tensor."""
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])  # update
    std = np.array([0.229, 0.224, 0.225])  # update
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.savefig(save_dir, format="png", bbox_inches='tight')  # tight stops savefig from cropping long title
    plt.show()
    plt.close('all')


self_data_path = '/home/hlcv_team030/hlcv_team030/sesame_plants'

self_data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(p=0.5),                
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}


self_image_datasets = {x:datasets.ImageFolder(os.path.join(self_data_path, x), self_data_transforms[x]) for x in ['train', 'val']}
self_dataset_sizes = {x: len(self_image_datasets[x]) for x in ['train', 'val']}
self_class_names = {0:'0',1:'90',2:'180',3:'270'} 

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
dtype =  torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor

im=None
for x in self_image_datasets['train']:
    im=x[0]
    break
print(len(self_image_datasets['val']))

def get_rot_mat(theta):
    theta = torch.tensor(theta)
    return torch.tensor([[torch.cos(theta), -torch.sin(theta), 0],
                         [torch.sin(theta), torch.cos(theta), 0]])

def rot_img(x, dtype):
    degrees=[0,np.pi/2,np.pi,np.pi*(3/2)]
    x=x.reshape(1,3,224,224)
    theta=random.choice(degrees) 
    # print("Rotation Angle",math.degrees(theta))
    rot_mat = get_rot_mat(theta)[None, ...].type(dtype).repeat(x.shape[0],1,1)
    grid = F.affine_grid(rot_mat,x.size()).type(dtype)
    x = F.grid_sample(x, grid.to(x.device))
    # torch.matmul(tensor1, tensor2)
    # rotated_img= torch.matmul(rot_mat,x)
    angles_dict={0:0,90:1,180:2,270:3}
    angle=math.degrees(theta)
    return x.reshape(3,224,224),angles_dict[angle]

plt.imshow(im.squeeze(0).permute(1,2,0)) 
plt.figure()
rotated_im,_ = rot_img(im, dtype) # Rotate image by 90 degrees.
plt.imshow(rotated_im.squeeze(0).permute(1,2,0))    

def get_labeled_data(data_set):
  degrees=[0,np.pi/2,np.pi,np.pi*(3/2)]
  labeled_data= {}
  for image in data_set:
    rotated_im, Angle = rot_img(image[0],dtype)
    labeled_data[rotated_im]=Angle
  return labeled_data
self_train=get_labeled_data(self_image_datasets['train'])  
self_val=get_labeled_data(self_image_datasets['val'])

self_train_data=list(map(list, self_train.items()))
self_val_data=list(map(list, self_val.items()))
self_train_loader= DataLoader(self_train_data,batch_size=4,shuffle=True,num_workers=2)     
self_val_loader=DataLoader(self_val_data,batch_size=4,shuffle=True,num_workers=2)  

self_custom_dataloader={'train':self_train_loader,'val': self_val_loader}

# Get a batch of training data
inputs, classes = next(iter(self_custom_dataloader['train']))

# print(inputs,classes)
# Make a grid from batch
out = torchvision.utils.make_grid(inputs)
# class_names=[0,np.pi/2,np.pi,np.pi*(3/2)]

imshow(out, title=[ self_class_names[x.item()] for x in classes])
# for i, j in custom_dataloader['train']:
#   print(i,j)

for inputs,labels in self_custom_dataloader['train']:
  print(inputs, labels.long())
  break

def self_train_model(model, custom_dataloader,criterion, optimizer, scheduler, epsilon = 1e-7,num_epochs=25):
    since = time.time()

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0
    

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Set model to training mode 
            else:
                model.eval()   # Set model to evaluate mode
                
            
            running_loss = 0.0
            running_corrects = 0

            # Iterate over data.
            for inputs, labels in custom_dataloader[phase]:
                
                labels=labels.long()
                inputs =  inputs.to(device)
                labels =  labels.to(device)
                
                
                
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    
                    loss = criterion(outputs, labels)
                    
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # statistics
                               
                running_loss += loss.item()
                running_corrects += torch.sum(preds == labels.data)
                
                # #F_1 score calculation
                
                # # F1_score = f1_score(labels.data, preds)
                # F1_score = f1_score(labels.cpu().data, preds.cpu(),average='micro')
               
            if phase == 'train':
                scheduler.step()
             
            # print(acc.item())
            epoch_loss = running_loss / self_dataset_sizes[phase]
            epoch_acc = running_corrects.double() / self_dataset_sizes[phase]

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(
                phase, epoch_loss, epoch_acc))

            # deep copy the model
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(
        time_elapsed // 60, time_elapsed % 60))
    print('Best val Acc: {:4f}'.format(best_acc))

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model

def visualize_model(model, num_images=6):
    was_training = model.training
    model.eval()
    images_so_far = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(custom_dataloader['val']):
            
            labels.long()
            inputs = inputs.to(device) #inputs.to(device=device, dtype=torch.long)
            labels =  labels.to(device)
            # inputs=torch.tensor(inputs,dtype=torch.long)
            # labels=torch.tensor(labels,dtype=torch.long)
            
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_so_far += 1
                ax = plt.subplot(num_images//2, 2, images_so_far)
                ax.axis('off')
                ax.set_title('predicted: {}'.format(class_names[preds[j]]))
                imshow(inputs.cpu().data[j])

                if images_so_far == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)        

model_ft = models.resnet50(pretrained=True,progress=True)
num_ftrs = model_ft.fc.in_features
model_ft.fc = nn.Linear(num_ftrs, len(self_class_names))

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)

# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

model_ft = self_train_model(model_ft,self_custom_dataloader,criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)


# remember to change the path before running! with '/' in the end
path = "/home/hlcv_team030/hlcv_team030/Image_Classification"
output_images_path = "/home/hlcv_team030/hlcv_team030/output_images"
# Folds are fixed, each folder contains split 4 folds in the training and 1 fold in the val
folds = ['/data/fold1', '/data/fold2', '/data/fold3', '/data/fold4', '/data/fold5']

# Methods/Functions


def load_data(data_dir,test_path):
    # This function loads the data and prepares it.
    # Expected format of directory: two directories 'train', 'val' each with a folder for each class

    # Data augmentation and normalization for training
    # Just normalization for validation
    data_transforms = {
        'train': transforms.Compose([
            transforms.RandomResizedCrop(224),
            transforms.RandomHorizontalFlip(p=0.5),
            # transforms.ColorJitter(brightness=0.5),
            # transforms.RandomGrayscale(p=0.2),
            ImageNetPolicy(),  # Randomly choose one of the best 24 Sub-policies on ImageNet
            # transforms.AutoAugment(),
            RandAugment(),
            # randaugment is adaptived from UDA tensorflow implementation: # https://github.com/jizongFox/uda
            # iaa.RandAugment(n=3, m=7),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'val': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),

        'test': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),

    }

    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                              data_transforms[x])
                      for x in ['train', 'val']}
    
    test_datasets={'test':datasets.ImageFolder(os.path.join(test_path, 'test'),
                                              data_transforms['test'])}
    
    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,
                                                  shuffle=True, num_workers=4)
                   for x in ['train', 'val']}
    
    test_loader= {'test': torch.utils.data.DataLoader(test_datasets['test'], batch_size=128,
                                                  shuffle=True, num_workers=4)}
    
    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}

    class_names = image_datasets['train'].classes

    return dataloaders,test_loader, dataset_sizes, class_names

def plot_train_val_acc(model_stats, title = "Training and validation accuracies", save_dir = output_images_path+"/train_val_acc.png"):
    plt.plot(model_stats['train_acc_history'], label='train')
    plt.plot(model_stats['val_acc_history'], label='val')
    plt.title(title)
    plt.xlabel('Epoch')
    plt.ylabel('Classification accuracy')
    plt.xlim([0, len(model_stats['val_acc_history'])])
    plt.ylim([0.2, 1])
    plt.legend()
    plt.savefig(save_dir, format="png", bbox_inches='tight')
    plt.show()
    plt.close('all')
    
def plot_loss_accuracy_curves(model_stats, title = "Loss Accuracy Curve", save_dir = output_images_path+"/loss_accuracy_curve.png"):
    plt.figure()
    plt.subplot(211)
    plt.plot(model_stats['loss_history'])
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    
    plt.subplot(212)
    plt.plot(model_stats['val_acc_history'], label='val')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.xlim([0, len(model_stats['val_acc_history'])])
    plt.legend()
    plt.title(title)
    plt.savefig(save_dir, format="png", bbox_inches='tight')
    plt.show()
    plt.close('all')

def mixup_data(x, y, alpha=1.0, use_cuda=True):
    '''Returns mixed inputs, pairs of targets, and lambda'''
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1

    batch_size = x.size()[0]
    if use_cuda:
        index = torch.randperm(batch_size).cuda()
    else:
        index = torch.randperm(batch_size)

    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam


def mixup_criterion(criterion, pred, y_a, y_b, lam):
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

def train_model(model, dataloaders,dataset_sizes, criterion, optimizer, scheduler, epsilon=1e-7, num_epochs=25):
    # This function trains the model

    since = time.time()
    model_stats = {'train_acc_history': [], 'val_acc_history': [], 'loss_history':[]}

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()  # Set model to evaluate mode

            TP, TN, FN, FP = 0, 0, 0, 0
            running_loss = 0.0
            running_corrects = 0

            # Iterate over data.
            all_preds, all_labels = [],[]
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                mixed_inputs, y_a, y_b, lam = mixup_data(inputs, labels)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    #outputs = model(inputs)
                    outputs = model(mixed_inputs)
                    _, preds = torch.max(outputs, 1)
                    #loss = criterion(outputs, labels)

                    #mixed_loss
                    loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)

                    all_preds.append(preds)
                    all_labels.append(labels)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # statistics

                running_loss += loss.item()
                #running_corrects += torch.sum(preds == labels.data)
                running_corrects += (lam * torch.sum(preds == y_a.data) ) + ( (1-lam) * torch.sum(preds == y_b.data) )
                

            if phase == 'train':
                scheduler.step()

            
            #corrects = np.ndarray([np.ndarray([np.sum(np.ndarray(all_preds == label) and np.ndarray(all_preds == all_labels))]) for label in class_names])/dataset_sizes[phase]

            #weigthed_epoch_acc = np.sum(np.ndarray(corrects) * np.ndarray([1.0, 0.6323529411764706, 0.7867647058823529]))/3

            
            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]
            #F1_score = f1_score(list(all_labels), list(all_preds), average='micro')
            F1_score = 0
            print('{} Loss: {:.4f} Acc: {:.4f}  F1_score:{:.4f}'.format(
                phase, epoch_loss, epoch_acc, F1_score))
            #print("Weighted accuracy: ",weighted_epoch_acc)

            if phase == 'train':
                model_stats['train_acc_history'].append(epoch_acc)
            else:
                model_stats['val_acc_history'].append(epoch_acc)
            model_stats['loss_history'].append(loss)

            # deep copy the model
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(
        time_elapsed // 60, time_elapsed % 60))
    print('Best val Acc: {:4f}'.format(best_acc))

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model, model_stats


def visualize_model(model, num_images=6, out_dir="", title=""):
    was_training = model.training
    model.eval()
    images_so_far = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(dataloaders['val']):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_so_far += 1
                ax = plt.subplot(num_images // 2, 2, images_so_far)
                ax.axis('off')
                ax.set_title('predicted: {}'.format(class_names[preds[j]]))
                imshow(inputs.cpu().data[j],
                       save_dir=out_dir + "{}_{}_predicted:{}.png".format(title, i, class_names[preds[j]]),
                       title="{}_{}_predicted:{}.png".format(title, i, class_names[preds[j]]))

                if images_so_far == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)

        
def test_model(test_loader, model):
	# TODO: implement test and test accuracy evaluation
	with torch.no_grad():
		TP,TN,FN,FP=0,0,0,0
		correct = 0
		total = 0
		all_labels, all_preds = [],[]
		for images, labels in test_loader['test']:
			images = images.to(device)
			labels = labels.to(device)
			outputs = model(images)
			_, predicted = torch.max(outputs.data, 1)
			total += labels.size(0)
			correct += (predicted == labels).sum().item()
			#print(labels.data)
			all_labels.append(labels)
			all_preds.append(predicted )
		#print(all_labels)
		#F1_score = f1_score(all_labels, all_preds, average='micro')
		F1_score = 0
		print('Accuracy of the network on the {} test images: {} % The F_score : {} '.format(total, 100 * correct / total, F1_score))
		
    
#itertae the folds :dataloaders

saved_model = model_ft
num_epochs = 5

for fold_number, fold in enumerate(folds):
    print("Fold:", fold)
    data_dir = path + fold
    dataloaders,test_loader, dataset_sizes, class_names = load_data(data_dir,path)
    print("Class names:", class_names)

    # Get a batch of training data
    inputs, classes = next(iter(dataloaders['train']))

    # Make a grid from batch
    out = torchvision.utils.make_grid(inputs)

    # show images
    imshow(out, title=[class_names[x] for x in classes], save_dir=output_images_path + "fold" + str(fold_number) + ".png")

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    # Visualize some training data
    model_ft = copy.deepcopy(saved_model)
    # Here the size of each output sample is set to 2.
    # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).
    model_ft.fc = nn.Linear(num_ftrs, len(class_names))

    model_ft = model_ft.to(device)

    criterion = nn.CrossEntropyLoss()

    # Observe that all parameters are being optimized
    optimizer_ft = optim.SGD(model_ft.parameters(), lr=1.0, momentum=0.9)

    # Decay LR by a factor of 0.1 every 7 epochs
    #exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)
    cos_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, num_epochs)
    
    print("Full Model:")
    print("Test before train")
    test_model(test_loader, model_ft)   
    model_ft, model_stats = train_model(model_ft,dataloaders ,dataset_sizes, criterion, optimizer_ft, cos_lr_scheduler, num_epochs=num_epochs)
    print("Test after training:")
    test_model(test_loader, model_ft)
    plot_train_val_acc(model_stats, save_dir = output_images_path+"/FT-fold{}-train_val_acc_plot.png".format(fold_number))
    plot_loss_accuracy_curves(model_stats, save_dir = output_images_path+"/FT-fold{}-loss_accuracy_plot.png".format(fold_number))


    visualize_model(model_ft, title="visualize_model_fc_only_fold{}".format(fold_number), out_dir=output_images_path)

    model_conv = torchvision.models.resnet50(pretrained=True, progress=True)
    for param in model_conv.parameters():
        param.requires_grad = False

    # Parameters of newly constructed modules have requires_grad=True by default
    num_ftrs = model_conv.fc.in_features
    model_conv.fc = nn.Linear(num_ftrs, len(class_names))

    model_conv = model_conv.to(device)

    criterion = nn.CrossEntropyLoss()

    # Observe that only parameters of final layer are being optimized as
    # opposed to before.
    optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=1.0, momentum=0.9)

    # Decay LR by a factor of 0.1 every 7 epochs
    #exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)
    cos_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_conv, num_epochs)
    print("Only FC layer")

    model_conv, model_stats = train_model(model_conv, dataloaders,dataset_sizes, criterion, optimizer_conv,
                             cos_lr_scheduler, num_epochs=num_epochs)

    plot_train_val_acc(model_stats, save_dir = output_images_path+"/FC-fold{}-train_val_acc_plot.png".format(fold_number))
    plot_loss_accuracy_curves(model_stats, save_dir = output_images_path+"/FC-fold{}-loss_accuracy_plot.png".format(fold_number))


    visualize_model(model_conv, title="visualize_model_fc_only_fold{}".format(fold_number), out_dir=output_images_path)

    plt.ioff()
    plt.show()
    plt.close('all')

    #test the model
    print("Test after training only last layer")
    test_model(test_loader, model_conv)

